{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "documentary-mozambique",
   "metadata": {},
   "source": [
    "## We are going to attempt to answer the question of whether or not the hot hands effect exists in Tennis, using first and second serves. We will look at the question backwards though, trying to see if the cold-hands effect exists. We want to answer these following questions:\n",
    "\n",
    "### 1. What is a player's chance of faulting their first serve, if their last first serve was a fault? \n",
    "### 2. What is a player's chance of double faulting, if they double faulted the last point?\n",
    "### 3. What is a player's chance of an ace, if they had an ace the last point?\n",
    "\n",
    "### This amounts to calculating three conditional probabilities, i.e., for 1 it is P(F|LF) where F is a fault on the current service and LF is a fault on the last service (LF for last-fault).\n",
    "### The \"cold hands\" effect exists if P(F|LF) > P(F|NF) , by a statistically significant amount (say 5 guassian sigma), where P(F|NF) is the probability of a fault on the first serve, given that the last first serve went in. (NF for no-fault).\n",
    "\n",
    "## An important point: We are going to use mock data to set up and verify the analysis, then we will dig up and find a data set that is optimal to use.\n",
    "### A couple of notes on why I made this choice. First, it will allow me to weed out any bugs by working with a dataset where I know the answer. Second, it will remove the possibility of biasing the analysis on real data. Third, is that although these datasets definitely exist -- which one to use is not immediately apparent. \n",
    "### At the pro level, the probability of an ace (and a double fault) is low (a typical number of aces in a given year is only 500, https://www.atptour.com/en/stats/aces/2019/all/all/ ). So point 2 and 3 might be exceedingly difficult to even investigate with confidence because we will be dealing with small number statistics. I.e., our constraints on the conditional probabilities will be weak. So making any kind of definitive conclusion will be hard. Looking at datasets at the college or highschool level would probably be more informative, (simply because the hot and cold hands effects, if they exist, are probably accentuated here) but then such datasets will be harder to come by.\n",
    "\n",
    "### So, without further ado, lets create this mock dataset, focusing on question 1 because:\n",
    "### Question 1 is likely to have the largest number of data points in the real dataset, and naively, the cold hands effect here should be just as present as it is in 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-trout",
   "metadata": {},
   "source": [
    "## Section 1, generating a dataset that will be replaceable by real data at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-hours",
   "metadata": {},
   "source": [
    "Generally, top pro players make about 65 percent of their first serves and 90 percent of their second serves. So we will generate, say 50 players whose aggregate first and second serve percentanges are random values between 50 and 70%. This is pretty representative of the top 50 players. https://www.atptour.com/en/stats/1st-serve/2019/all/all/\n",
    "\n",
    "We are including the complicating factor here of multiple players because we will certainly need to aggregate over players in the real data in order to build up the sample size required.\n",
    "\n",
    "We want to be intelligent about how we structure this dataset. As with all questions, how you structure your data can be extremely hindering, or extremely enlightening. I personally prefer hefty datastructures that are easy to navigate. One could do this with a SQL table or something the like, but I will tackle with astropy tables because of their myriad of grouping and sorting abilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alternative-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "\n",
    "num_players = 50\n",
    "first_serve_chance_range = (0.5, 0.7)\n",
    "player_table = {'player_id': np.arange(50), \n",
    "                'first_serve_chance': np.round(np.random.uniform(low=min(first_serve_chance_range), high=max(first_serve_chance_range), size=num_players), 3)}\n",
    "player_table = Table(player_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conceptual-ontario",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=5</i>\n",
       "<table id=\"table140203378538912\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>player_id</th><th>first_serve_chance</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>float64</th></tr></thead>\n",
       "<tr><td>0</td><td>0.607</td></tr>\n",
       "<tr><td>1</td><td>0.581</td></tr>\n",
       "<tr><td>2</td><td>0.625</td></tr>\n",
       "<tr><td>3</td><td>0.648</td></tr>\n",
       "<tr><td>4</td><td>0.542</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "player_id first_serve_chance\n",
       "  int64        float64      \n",
       "--------- ------------------\n",
       "        0              0.607\n",
       "        1              0.581\n",
       "        2              0.625\n",
       "        3              0.648\n",
       "        4              0.542"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_table[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-verse",
   "metadata": {},
   "source": [
    "Great, now we have some random players with identification integers 0, 1..., 50 (we would replace their names with these integers in the real data set), and each has some aggregate first serve percentage. This would be fetched, in the real data, from something like the ATP website https://www.atptour.com/en/stats/aces/2019/all/all/ .\n",
    "\n",
    "Now, each player will play order-of-magnitude the same number of matches in a year (e.g., somewhere between 40 and 80). But we will need to take this into account when we assess the statistics, so we want to add this complication to the mock data as well. This will be the last complication we add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "administrative-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "serves_per_match = 150\n",
    "num_serves_range = (serves_per_match * 40, serves_per_match* 80)\n",
    "\n",
    "player_table['num_serves_on_record'] = np.random.randint(low=min(num_serves_range), high=max(num_serves_range), size=len(player_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "documented-confusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=5</i>\n",
       "<table id=\"table140203378501136\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>player_id</th><th>first_serve_chance</th><th>num_serves_on_record</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>float64</th><th>int64</th></tr></thead>\n",
       "<tr><td>0</td><td>0.607</td><td>11075</td></tr>\n",
       "<tr><td>1</td><td>0.581</td><td>8946</td></tr>\n",
       "<tr><td>2</td><td>0.625</td><td>8815</td></tr>\n",
       "<tr><td>3</td><td>0.648</td><td>6772</td></tr>\n",
       "<tr><td>4</td><td>0.542</td><td>10927</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "player_id first_serve_chance num_serves_on_record\n",
       "  int64        float64              int64        \n",
       "--------- ------------------ --------------------\n",
       "        0              0.607                11075\n",
       "        1              0.581                 8946\n",
       "        2              0.625                 8815\n",
       "        3              0.648                 6772\n",
       "        4              0.542                10927"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_table[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-studio",
   "metadata": {},
   "source": [
    "## Now we have all the aggregate data in hand to generate a mock data set. We will make a dataset class to generate these fake data, so that we can run the analysis for two different magnitudes of cold-hand effects:\n",
    "Recall that we are defining P(F|LF) as the probability of a fault, conditional on the last serve being a fault as well. And P(F|NF) as the probability of faulting this first serve, given that the last first serve was not a fault.\n",
    "\n",
    "## A cold hands effect of 10 % -- meaning P(F|LF) - P(F|NF)  = 0.1\n",
    "## And a cold effects of 0% -- meaning P(F|LF) - P(F|NF) = 0.0\n",
    "\n",
    "### The goal is that, through our analysis later on, we can recover both instances of the cold-hands effect.\n",
    "### Remember that this is all statistical. If we succeed, we won't recover P(F|LF) - P(F|NF) = 0.1 for case 1, we will recover some posterior estimate that is consistent with (i.e., within 1 sigma of) 0.1\n",
    "\n",
    "### We will make these mock data such that we have already split the data by set. We wouldn't expect as large of a cold/hot hands effect that extends between one service set and the next (which could be separated by tens of minutes). So we want to have our data and analysis reflect that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-johnson",
   "metadata": {},
   "source": [
    "We are going to simulate a set of serves using a monte carlo simulation. This is not the fastest way in terms of computation time to do this, but it is a reliable way that is very very simple to code up. Simple = less chance for bugs, so we are going to go with this method.\n",
    "\n",
    "After we code up the monte carlo method, we will write a class for the MockData to keep everything organized and accessible in a nice object-oriented way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_serves(num_serves, first_serve_chance, cold_hands_magnitude):\n",
    "    \"\"\"\n",
    "    Generate a long list of first serve statistics. 1 means the first serve went in, 0 means a fault.\n",
    "    \"\"\"\n",
    "    serve_chance = [1 - first_serve_chance, first_serve_chance]\n",
    "    serve_data = [np.random.choice([0, 1], p=serve_chance)]\n",
    "    for i in num_serves:\n",
    "        \n",
    "    \n",
    "def split_serves_into_sets(serve_data, num_serves_per_set)\n",
    "    \"\"\"\n",
    "    Tennis is played in discrete sets. This function will split the long 1d list of service statistics into discrete sets.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockData(object):\n",
    "    def __init__(self, player_table, serves_per_set=5, cold_hands_magnitude=0.1, match_data=None):\n",
    "        self.player_table = player_table\n",
    "        self.serves_per_set = serves_per_set\n",
    "        self.cold_hands_magnitude = cold_hands_magnitude\n",
    "        if match_data is None:\n",
    "            self.serve_data = self.init_serve_data()\n",
    "\n",
    "    def init_serve_data(self):\n",
    "        serve_data = {i: None for i in self.player_table['player_id']}\n",
    "        for i in serve_data.keys():\n",
    "            player_data = self.player_table[self.player_table['player_id'] == i]\n",
    "            serve_data[i] = simulate_serves(player_data['num_serves_on_record'],\n",
    "                                            player_data['first_serve_chance'],\n",
    "                                            self.cold_hands_magnitude)\n",
    "            serve_data[i] = split_serves_into_sets(serve_data[i], self.serves_per_set)\n",
    "\n",
    "            \n",
    "    def __call__(self, player_id):\n",
    "        return self.serve_data[player_id]\n",
    "\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
